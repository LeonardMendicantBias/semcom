{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e02698f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6745868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.reader import KineticDataset\n",
    "\n",
    "from src.vqgan import ViTVQGAN\n",
    "from src.my_model import MaskCode\n",
    "from src.trainer import AttentionMaskModeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9811e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/246534"
     ]
    }
   ],
   "source": [
    "path = \"/mnt/e/kinetics-dataset/k400\"\n",
    "split = \"train\"\n",
    "\n",
    "ds = KineticDataset(\n",
    "    path, split,\n",
    "    n_frames=16,\n",
    ")\n",
    "ds_loader = DataLoader(\n",
    "    ds, 1, True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eddfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in ds_loader:\n",
    "    code, _ = batch\n",
    "    break\n",
    "\n",
    "B, T, HW = code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f38ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonard/anaconda3/envs/semcom/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:210: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "# lightning_model = AttentionMaskModeling.load_from_checkpoint(\n",
    "#     \"./trained/semcom-epoch=14-train_acc=0.96.ckpt\"\n",
    "# )#.to(torch.float16)\n",
    "\n",
    "lightning_model = AttentionMaskModeling(\n",
    "    model=MaskCode(\n",
    "\t\twindow_size=(3, 3),\n",
    "\t\tlength=32, height=32, width=32,\n",
    "\t\tdepth=4, heads=8, dim=128, embed_dim=32,\n",
    "\t\tn_codes=8192,\n",
    "\t), \n",
    "    top_p=0.95\n",
    ")\n",
    "lightning_model.cuda()\n",
    "_batch = batch[0].cuda(), None\n",
    "# lightning_model.training_step(_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "910291d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.5 ms ± 15.3 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def _test(model, data, device=\"cpu\", dtype=torch.float32):\n",
    "    # with torch.autocast(device_type=device, dtype=dtype), torch.no_grad():\n",
    "    model.get_mask_from_logits(data)\n",
    "\n",
    "%timeit _test(lightning_model, _batch[0], \"cuda\", torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_2(model, img):\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        model(img)\n",
    "\n",
    "vitvq = ViTVQGAN.get_vit_vqgan_base()\n",
    "vitvq.init_from_ckpt(\"./checkpoint/imagenet_vitvq_base.ckpt\")\n",
    "vitvq.eval()\n",
    "vitvq.cuda()\n",
    "\n",
    "data = torch.rand((1, 3, 256, 256)).cuda()\n",
    "\n",
    "%timeit _test_2(vitvq, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17903174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.5 ms ± 149 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def _test(model, data, device=\"cpu\", dtype=torch.float32):\n",
    "    model.reset_cache()\n",
    "    # with torch.autocast(device_type=device, dtype=dtype):\n",
    "    for d in data:\n",
    "        model.get_mask_from_logits(d[None, ...], use_cache=True)\n",
    "\n",
    "         \n",
    "%timeit _test(lightning_model, _batch[0], \"cuda\", torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[None, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49e4f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "------------------------------\n",
      "kv torch.Size([16384, 8, 10, 16]) torch.Size([16384, 8, 10, 16])\n",
      "kv torch.Size([16384, 8, 10, 16]) torch.Size([16384, 8, 10, 16])\n",
      "------------------------------\n",
      "kv torch.Size([1024, 8, 17, 16]) torch.Size([1024, 8, 17, 16])\n",
      "kv torch.Size([1024, 8, 17, 16]) torch.Size([1024, 8, 17, 16])\n",
      "------------------------------\n",
      "kv torch.Size([16384, 8, 10, 16]) torch.Size([16384, 8, 10, 16])\n",
      "kv torch.Size([16384, 8, 10, 16]) torch.Size([16384, 8, 10, 16])\n",
      "------------------------------\n",
      "kv torch.Size([1024, 8, 17, 16]) torch.Size([1024, 8, 17, 16])\n",
      "kv torch.Size([1024, 8, 17, 16]) torch.Size([1024, 8, 17, 16])\n",
      "------------------------------\n",
      "kv torch.Size([16384, 8, 10, 16]) torch.Size([16384, 8, 10, 16])\n",
      "kv torch.Size([16384, 8, 10, 16]) torch.Size([16384, 8, 10, 16])\n",
      "------------------------------\n",
      "kv torch.Size([1024, 8, 17, 16]) torch.Size([1024, 8, 17, 16])\n",
      "kv torch.Size([1024, 8, 17, 16]) torch.Size([1024, 8, 17, 16])\n",
      "------------------------------\n",
      "kv torch.Size([16384, 8, 10, 16]) torch.Size([16384, 8, 10, 16])\n",
      "kv torch.Size([16384, 8, 10, 16]) torch.Size([16384, 8, 10, 16])\n",
      "------------------------------\n",
      "kv torch.Size([1024, 8, 17, 16]) torch.Size([1024, 8, 17, 16])\n",
      "kv torch.Size([1024, 8, 17, 16]) torch.Size([1024, 8, 17, 16])\n"
     ]
    }
   ],
   "source": [
    "lightning_model.reset_cache()\n",
    "with torch.autocast(device_type=\"cuda\", dtype=torch.float32), torch.no_grad():\n",
    "    for i, frame in enumerate(_batch[0]):\n",
    "        print(\"step:\", i)\n",
    "        lightning_model.get_mask_from_logits(frame[None, ...], use_cache=True)\n",
    "\n",
    "        # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
