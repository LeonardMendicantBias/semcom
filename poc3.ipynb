{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39887209",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33188c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.reader import KineticDataset, KineticDatasetVideo\n",
    "\n",
    "from src.vqgan import ViTVQGAN\n",
    "from src.my_model import MaskCode, Encoder, Decoder, MaskVideo\n",
    "from src.trainer import AttentionMaskModeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c73813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "path = \"/mnt/e/kinetics-dataset/k400\"\n",
    "split = \"train\"\n",
    "\n",
    "# ds = KineticDatasetVideo(\n",
    "#     path, split,\n",
    "#     n_frames=16,\n",
    "# )\n",
    "ds = KineticDatasetVideo.get_ds(path, split, 16)\n",
    "ds_loader = DataLoader(\n",
    "    ds, 2, True, \n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b368542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_finetune = False\n",
    "image_size = (256, 256)\n",
    "patch_size = (8, 8)\n",
    "depth, heads, dim, embed_dim = 12, 12, 768, 32\n",
    "\n",
    "window_size = (3, 3)\n",
    "length, height, width = 32, 32, 32\n",
    "temporal_depth, temporal_heads, temporal_dim = 4, 8, 128\n",
    "n_codes=8192\n",
    "\n",
    "vitvq_path = \"./checkpoint/imagenet_vitvq_base.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342703ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = AttentionMaskModeling(\n",
    "    model=MaskVideo(\n",
    "        is_finetune=is_finetune,\n",
    "        image_size=image_size, patch_size=patch_size,\n",
    "        depth=depth, heads=heads, dim=dim,\n",
    "        n_codes=n_codes, embed_dim=embed_dim,\n",
    "\n",
    "        window_size=window_size,\n",
    "        length=length, height=height, width=width,\n",
    "        temporal_depth=temporal_depth, temporal_heads=temporal_heads, temporal_dim=temporal_dim,\n",
    "\n",
    "        drop_prob=0.1, depth_prob=0.1,\n",
    "        vitvq_path=vitvq_path\n",
    "\t), \n",
    "    top_p=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598cbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskVideo(\n",
    "    is_finetune=is_finetune,\n",
    "    image_size=image_size, patch_size=patch_size,\n",
    "    depth=depth, heads=heads, dim=dim,\n",
    "    n_codes=n_codes, embed_dim=embed_dim,\n",
    "\n",
    "    window_size=window_size,\n",
    "    length=length, height=height, width=width,\n",
    "    temporal_depth=temporal_depth, temporal_heads=temporal_heads, temporal_dim=temporal_dim,\n",
    "\n",
    "    drop_prob=0.1, depth_prob=0.1,\n",
    "    vitvq_path=vitvq_path\n",
    ")\n",
    "encoder = model.encoder\n",
    "decoder = model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoPE (at both encoder and decoder)\n",
    "# Dedicate class for Transformer (Optional)\n",
    "# Cache inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9700c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "with torch.no_grad():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
